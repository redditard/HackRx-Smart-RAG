# Copy this file to .env and fill in your actual API keys

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Pinecone Configuration  
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-east-1-aws
PINECONE_INDEX_NAME=hackrx-documents

# Local LLM Configuration (for LM Studio - OpenAI Compatible)
LOCAL_LLM_ENDPOINT=http://localhost:1234/v1/chat/completions
LOCAL_LLM_MODEL=lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF
LOCAL_LLM_TIMEOUT=120

# Default Model Selection (can be overridden by command line)
# Options: 'gemini' or 'local'
DEFAULT_MODEL_TYPE=gemini
